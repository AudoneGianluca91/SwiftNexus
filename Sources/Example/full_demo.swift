import Foundation
import PyWrapRuntime
import RWrapRuntime

// MARK: â€“ Python side wrappers (autoâ€‘generated by PyWrapGenerator)
@pywrap(module: "numpy", name: "array")
struct NDArray {}
@pywrap(module: "torch", name: "Tensor")
struct Tensor {}
@pywrap(module: "torch", name: "rand") // function wrapper for torch.rand
struct TorchRand {}

// MARK: â€“ R side wrappers (autoâ€‘generated by RWrapGenerator)
@rwrap(package: "stats", name: "lm")
struct LM {}

// MARK: â€“ Example starts here
print("ðŸª„ Swiftâ€‘Pythonâ€‘R demo (zeroâ€‘copy, GPU, concurrency)\n")

// 1. NumPy array created in Python, analysed in Swift via zeroâ€‘copy pointer
let np = import("numpy")
let a = NDArray.new(np.random.rand(1_000_000))
let swiftMax = a.withUnsafeBufferPointer { ptr in ptr.max()! }
print("NumPy â†’ Swift zeroâ€‘copy max:", swiftMax)

// 2. Same data back to Python after Swift transformation
let doubled = NDArray.new(a._py * 2)
print("First three elements after *2:", doubled._py[0..<3])

// 3. R linear model using builtâ€‘in dataset
let lm = LM.new("Sepal.Width ~ Sepal.Length", data: "iris")
print("R lm coefficients â†’", lm.summary().asString())

// 4. PyTorch GPU tensor (CUDA or Metal Performance Shaders)
let torch = import("torch")
let device = torch.cuda.is_available().boolValue ? "cuda" : (torch.backends.mps.is_available().boolValue ? "mps" : "cpu")
let t = Tensor.new(torch.rand( (1000, 1000), keywordArguments: ["device": device]))
print("PyTorch tensor device:", device)
print("t.mean() â†’", t._py.mean().item())

// 5. Concurrency: run five Python sleeps in parallel using Swift TaskGroup
await withTaskGroup(of: Double.self) { group in
    for i in 0..<5 {
        group.addTask {
            let time = Double.random(in: 0.5...1.5)
            import("time").sleep(time)
            return time
        }
    }
    var total: Double = 0
    for await t in group { total += t }
    print("Parallel Python sleeps total wallâ€‘time â‰ˆ", total)
}

// 6. Optional Metal kernel (macOS/iOS) â€“ add two vectors on GPU, zeroâ€‘copy from NumPy
#if canImport(Metal)
import Metal
if let dev = MTLCreateSystemDefaultDevice() {
    let lib = try dev.makeDefaultLibrary(source: "kernel void add(device const double* a [[buffer(0)]], device const double* b [[buffer(1)]], device double* c [[buffer(2)]], uint id [[thread_position_in_grid]]) { c[id] = a[id] + b[id]; }", options: nil)
    let fn = lib.makeFunction(name: "add")!
    let pipe = try dev.makeComputePipelineState(function: fn)

    let x = NDArray.new(np.arange(1_048_576))
    let y = NDArray.new(np.arange(1_048_576, 2_097_152))

    let len = 1_048_576 * MemoryLayout<Double>.stride
    let bx = dev.makeBuffer(bytesNoCopy: x._py.data, length: len, options: [], deallocator: nil)!
    let by = dev.makeBuffer(bytesNoCopy: y._py.data, length: len, options: [], deallocator: nil)!
    let out = dev.makeBuffer(length: len, options: [])!

    let cmdQ = dev.makeCommandQueue()!
    let cmd = cmdQ.makeCommandBuffer()!
    let enc = cmd.makeComputeCommandEncoder()!

    enc.setComputePipelineState(pipe)
    enc.setBuffer(bx, offset: 0, index: 0)
    enc.setBuffer(by, offset: 0, index: 1)
    enc.setBuffer(out, offset: 0, index: 2)

    let grid = MTLSize(width: 1_048_576, height: 1, depth: 1)
    let threadsPerThreadgroup = MTLSize(width: 256, height: 1, depth: 1)
    enc.dispatchThreads(grid, threadsPerThreadgroup: threadsPerThreadgroup)
    enc.endEncoding()
    cmd.commit(); cmd.waitUntilCompleted()

    // Wrap result as NumPy without copy
    let resultPtr = out.contents().assumingMemoryBound(to: Double.self)
    let resPy = np.frombuffer(PyWrapRuntime.import("builtins").bytes(resultPtr, len), dtype: np.float64)
    print("GPU add first 3 â†’", resPy[0..<3])
}
#endif

print("\nâœ… Finished demo.")
